{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FfP6qOd7PaEm",
        "outputId": "ad26e231-d767-44a4-ffb0-de7abed18348"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import datetime\n",
        "\n",
        "# Verificar se CUDA está disponível\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Usando dispositivo: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 1. Coleta dos dados ===\n",
        "ticker = 'NVDA'\n",
        "start_date = '2022-01-01'\n",
        "end_date = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "df = yf.download(ticker, start=start_date, end=end_date)\n",
        "df = df[['Close']]\n",
        "df.dropna(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 2. Normalização dos dados ===\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 3. Classe Dataset personalizada ===\n",
        "class StockDataset(Dataset):\n",
        "    def __init__(self, data, window_size=60):\n",
        "        self.data = data\n",
        "        self.window_size = window_size\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.window_size\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx:idx + self.window_size, 0]\n",
        "        y = self.data[idx + self.window_size, 0]\n",
        "        return torch.FloatTensor(x), torch.FloatTensor([y])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 4. Divisão dos dados ===\n",
        "window_size = 60\n",
        "split = int(len(scaled_data) * 0.8)  # 80% treino, 20% validação\n",
        "\n",
        "train_data = scaled_data[:split + window_size]\n",
        "test_data = scaled_data[split:]\n",
        "\n",
        "train_dataset = StockDataset(train_data, window_size)\n",
        "test_dataset = StockDataset(test_data, window_size)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 5. Definição do modelo LSTM ===\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=50, num_layers=2, dropout=0.2):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
        "                           batch_first=True, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_length, input_size)\n",
        "        x = x.unsqueeze(-1)  # Adiciona dimensão de features\n",
        "        \n",
        "        # Inicializar estados ocultos\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
        "        \n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        \n",
        "        # Usar apenas a última saída temporal\n",
        "        out = self.dropout(out[:, -1, :])\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 6. Instanciar modelo, loss e otimizador ===\n",
        "model = LSTMModel().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Arquitetura do modelo:\")\n",
        "print(model)\n",
        "print(f\"\\nTotal de parâmetros: {sum(p.numel() for p in model.parameters())}\")\n",
        "\n",
        "# === 7. Função de treinamento ===\n",
        "def train_model(model, train_loader, test_loader, epochs=20):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Treinamento\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_loss += loss.item()\n",
        "        \n",
        "        # Validação\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y in test_loader:\n",
        "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "                outputs = model(batch_x)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                val_loss += loss.item()\n",
        "        \n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "        \n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        \n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}')\n",
        "    \n",
        "    return train_losses, val_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 8. Treinamento ===\n",
        "print(\"Iniciando treinamento...\")\n",
        "train_losses, val_losses = train_model(model, train_loader, test_loader, epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 9. Previsões ===\n",
        "model.eval()\n",
        "predictions = []\n",
        "actuals = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_x, batch_y in test_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        outputs = model(batch_x)\n",
        "        predictions.extend(outputs.cpu().numpy())\n",
        "        actuals.extend(batch_y.cpu().numpy())\n",
        "\n",
        "# Converter para numpy arrays\n",
        "predictions = np.array(predictions).reshape(-1, 1)\n",
        "actuals = np.array(actuals).reshape(-1, 1)\n",
        "\n",
        "# Desnormalizar\n",
        "predictions = scaler.inverse_transform(predictions)\n",
        "actuals = scaler.inverse_transform(actuals)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 10. Avaliação ===\n",
        "mae = mean_absolute_error(actuals, predictions)\n",
        "rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
        "mape = mean_absolute_percentage_error(actuals, predictions)\n",
        "\n",
        "print(f\"\\nAvaliação do modelo:\")\n",
        "print(f\"MAE  = {mae:.2f}\")\n",
        "print(f\"RMSE = {rmse:.2f}\")\n",
        "print(f\"MAPE = {mape*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 11. Plots ===\n",
        "# Plot das previsões\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(actuals, label='Preço Real', alpha=0.7)\n",
        "plt.plot(predictions, label='Previsão', alpha=0.7)\n",
        "plt.title('Previsão do Preço das Ações da NVIDIA (LSTM - PyTorch)')\n",
        "plt.xlabel('Dias')\n",
        "plt.ylabel('Preço (USD)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot das losses\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Evolução da Loss Durante o Treinamento')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 12. Salvar o modelo ===\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'scaler': scaler,\n",
        "    'window_size': window_size,\n",
        "    'model_params': {\n",
        "        'input_size': 1,\n",
        "        'hidden_size': 50,\n",
        "        'num_layers': 2,\n",
        "        'dropout': 0.2\n",
        "    }\n",
        "}, 'lstm_model_pytorch.pth')\n",
        "\n",
        "print(\"\\nModelo salvo como 'lstm_model_pytorch.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# === 13. Exemplo de como carregar o modelo ===\n",
        "def load_model_for_inference(model_path):\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    \n",
        "    # Recriar modelo\n",
        "    model = LSTMModel(**checkpoint['model_params']).to(device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    return model, checkpoint['scaler'], checkpoint['window_size']\n",
        "\n",
        "print(\"\\nPara carregar o modelo posteriormente, use:\")\n",
        "print(\"model, scaler, window_size = load_model_for_inference('lstm_model_pytorch.pth')\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
